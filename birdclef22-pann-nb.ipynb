{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport gc\nimport os\nimport sys\nimport math\nimport random\nimport warnings\nimport ast\n!pip install timm==0.4.5 torchlibrosa pytorch-lightning==1.3.4\n!pip install wget\nimport wget\n\nimport albumentations as A\nimport matplotlib.pyplot as plt\nimport cv2\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport soundfile as sf\nimport timm\nfrom timm.models.layers import to_2tuple,trunc_normal_\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as torchdata\n\nfrom pathlib import Path\nfrom typing import List\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.callbacks import EarlyStopping\n\nimport wandb\nfrom pytorch_lightning.loggers import WandbLogger\n\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations.core.transforms_interface import ImageOnlyTransform\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom timm.models.layers import SelectAdaptivePool2d\nfrom torch.optim.optimizer import Optimizer\nfrom torchlibrosa.stft import LogmelFilterBank, Spectrogram\nfrom torchlibrosa.augmentation import SpecAugmentation\nimport torchaudio\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb-api-key\")\nwandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:26:29.875718Z","iopub.execute_input":"2022-04-26T16:26:29.876108Z","iopub.status.idle":"2022-04-26T16:27:04.017013Z","shell.execute_reply.started":"2022-04-26T16:26:29.875992Z","shell.execute_reply":"2022-04-26T16:27:04.016269Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)  # type: ignore\n    torch.backends.cudnn.deterministic = True  # type: ignore\n    torch.use_deterministic_algorithms = True\n    torch.backends.cudnn.benchmark = False  # type: ignore","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:27:04.019159Z","iopub.execute_input":"2022-04-26T16:27:04.019424Z","iopub.status.idle":"2022-04-26T16:27:04.025697Z","shell.execute_reply.started":"2022-04-26T16:27:04.019377Z","shell.execute_reply":"2022-04-26T16:27:04.024347Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Download the pretrained PANN weights\n!wget https://zenodo.org/record/3987831/files/Cnn14_emb128_mAP%3D0.412.pth?download=1 ","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:27:04.027194Z","iopub.execute_input":"2022-04-26T16:27:04.027489Z","iopub.status.idle":"2022-04-26T16:29:02.727903Z","shell.execute_reply.started":"2022-04-26T16:27:04.027453Z","shell.execute_reply":"2022-04-26T16:29:02.727151Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!mv Cnn14_emb128_mAP=0.412.pth?download=1 Cnn14_emb128_mAP=0.412.pth ","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:02.730633Z","iopub.execute_input":"2022-04-26T16:29:02.730903Z","iopub.status.idle":"2022-04-26T16:29:03.396504Z","shell.execute_reply.started":"2022-04-26T16:29:02.730877Z","shell.execute_reply":"2022-04-26T16:29:03.395487Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    ######################\n    # Globals #\n    ######################\n    exp_num = 14\n    seed = 777\n    epochs = 40\n    train = True\n    folds = [0]\n    img_size = 224\n\n    ######################\n    # Dataset #\n    ######################\n    period = 10\n    n_mels = 128\n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n        \"n_mels\": 224,\n        \"fmin\": 20,\n        \"fmax\": 16000\n    }\n\n    target_columns = [\n        'afrsil1', 'akekee', 'akepa1', 'akiapo', 'akikik', 'amewig',\n       'aniani', 'apapan', 'arcter', 'barpet', 'bcnher', 'belkin1',\n       'bkbplo', 'bknsti', 'bkwpet', 'blkfra', 'blknod', 'bongul',\n       'brant', 'brnboo', 'brnnod', 'brnowl', 'brtcur', 'bubsan',\n       'buffle', 'bulpet', 'burpar', 'buwtea', 'cacgoo1', 'calqua',\n       'cangoo', 'canvas', 'caster1', 'categr', 'chbsan', 'chemun',\n       'chukar', 'cintea', 'comgal1', 'commyn', 'compea', 'comsan',\n       'comwax', 'coopet', 'crehon', 'dunlin', 'elepai', 'ercfra',\n       'eurwig', 'fragul', 'gadwal', 'gamqua', 'glwgul', 'gnwtea',\n       'golphe', 'grbher3', 'grefri', 'gresca', 'gryfra', 'gwfgoo',\n       'hawama', 'hawcoo', 'hawcre', 'hawgoo', 'hawhaw', 'hawpet1',\n       'hoomer', 'houfin', 'houspa', 'hudgod', 'iiwi', 'incter1',\n       'jabwar', 'japqua', 'kalphe', 'kauama', 'laugul', 'layalb',\n       'lcspet', 'leasan', 'leater1', 'lessca', 'lesyel', 'lobdow',\n       'lotjae', 'madpet', 'magpet1', 'mallar3', 'masboo', 'mauala',\n       'maupar', 'merlin', 'mitpar', 'moudov', 'norcar', 'norhar2',\n       'normoc', 'norpin', 'norsho', 'nutman', 'oahama', 'omao', 'osprey',\n       'pagplo', 'palila', 'parjae', 'pecsan', 'peflov', 'perfal',\n       'pibgre', 'pomjae', 'puaioh', 'reccar', 'redava', 'redjun',\n       'redpha1', 'refboo', 'rempar', 'rettro', 'ribgul', 'rinduc',\n       'rinphe', 'rocpig', 'rorpar', 'rudtur', 'ruff', 'saffin', 'sander',\n       'semplo', 'sheowl', 'shtsan', 'skylar', 'snogoo', 'sooshe',\n       'sooter1', 'sopsku1', 'sora', 'spodov', 'sposan', 'towsol',\n       'wantat1', 'warwhe1', 'wesmea', 'wessan', 'wetshe', 'whfibi',\n       'whiter', 'whttro', 'wiltur', 'yebcar', 'yefcan', 'zebdov']\n\n    ######################\n    # Loaders #\n    ######################\n    loader_params = {\n        \"train\": {\n            'batch_size': 16,\n            'shuffle': True,\n            'num_workers': 4,\n            'pin_memory': True,\n            'drop_last': True,\n        },\n        \"valid\": {\n            'batch_size': 8,\n            'shuffle': False,\n            'num_workers': 4,\n            'pin_memory': True,\n            'drop_last': False,\n        }\n    }\n\n    ######################\n    # Split #\n    ######################\n    split = \"StratifiedKFold\"\n    split_params = {\n        \"n_splits\": 5,\n        \"shuffle\": True,\n        \"random_state\": 777\n    }\n\n    ######################\n    # Model #\n    ######################\n    base_model_name = \"\"\n    pooling = \"max\"\n    pretrained = True\n    num_classes = 152\n    in_channels = 1\n\n    ######################\n    # Optimizer #\n    ######################\n    optimizer_name = \"Adam\"\n    base_optimizer = \"Adam\"\n    optimizer_params = {\n        \"lr\": 1e-4,\n    }\n\n    ######################\n    # Scheduler #\n    ######################\n    scheduler_name = \"CosineAnnealingLR\"\n    scheduler_params = {\n        \"T_max\": 10\n    }","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.398504Z","iopub.execute_input":"2022-04-26T16:29:03.398785Z","iopub.status.idle":"2022-04-26T16:29:03.418051Z","shell.execute_reply.started":"2022-04-26T16:29:03.398748Z","shell.execute_reply":"2022-04-26T16:29:03.417286Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"CFG = CFG()\nos.environ['TORCH_HOME'] = './'","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.419557Z","iopub.execute_input":"2022-04-26T16:29:03.420010Z","iopub.status.idle":"2022-04-26T16:29:03.426764Z","shell.execute_reply.started":"2022-04-26T16:29:03.419800Z","shell.execute_reply":"2022-04-26T16:29:03.426077Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.428168Z","iopub.execute_input":"2022-04-26T16:29:03.428657Z","iopub.status.idle":"2022-04-26T16:29:03.439422Z","shell.execute_reply.started":"2022-04-26T16:29:03.428619Z","shell.execute_reply":"2022-04-26T16:29:03.438736Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"DATA_DIR = Path(\"../input/\")\nMAIN_DATA_DIR = DATA_DIR / 'birdclef-2022/'\nOUTPUT_DIR = Path('./')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.441470Z","iopub.execute_input":"2022-04-26T16:29:03.442246Z","iopub.status.idle":"2022-04-26T16:29:03.446665Z","shell.execute_reply.started":"2022-04-26T16:29:03.442210Z","shell.execute_reply":"2022-04-26T16:29:03.445948Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"######################\n# Data #\n######################\ntrain_datadir = MAIN_DATA_DIR / 'train_audio'\ntrain_csv = MAIN_DATA_DIR / 'train_metadata.csv'","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.448063Z","iopub.execute_input":"2022-04-26T16:29:03.448807Z","iopub.status.idle":"2022-04-26T16:29:03.455932Z","shell.execute_reply.started":"2022-04-26T16:29:03.448768Z","shell.execute_reply":"2022-04-26T16:29:03.455174Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\nif DEBUG:\n    CFG.epochs = 1","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.459497Z","iopub.execute_input":"2022-04-26T16:29:03.460104Z","iopub.status.idle":"2022-04-26T16:29:03.464807Z","shell.execute_reply.started":"2022-04-26T16:29:03.460070Z","shell.execute_reply":"2022-04-26T16:29:03.464144Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## My func","metadata":{}},{"cell_type":"code","source":"class WaveformDataset(torchdata.Dataset):\n    def __init__(self,\n                 df: pd.DataFrame,\n                 datadir: Path,\n                 img_size=224,\n                 period=10,\n                 validation=False,\n                 test=False):\n        self.df = df\n        self.datadir = datadir\n        self.img_size = img_size\n        self.period = period\n        self.validation = validation\n        self.test = test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx: int):\n        if ~self.test:\n            sample = self.df.loc[idx, :]\n            wav_name = sample[\"filename\"]\n            ebird_code = sample[\"primary_label\"]\n            primary_label = sample[\"primary_labels\"]\n            secondary_labels = sample[\"secondary_labels\"]\n            y, sr = sf.read(self.datadir / wav_name)\n            y = np.array(y)\n            if len(y.shape) == 2:\n                y = np.mean(y, axis=1)\n\n            len_y = len(y)\n            effective_length = sr * self.period\n            if len_y < effective_length:\n                new_y = np.zeros(effective_length, dtype=y.dtype)\n                if not self.validation:\n                    start = np.random.randint(effective_length - len_y)\n                else:\n                    start = 0\n                new_y[start:start + len_y] = y\n                y = new_y.astype(np.float32)\n            elif len_y > effective_length:\n                if not self.validation:\n                    start = np.random.randint(len_y - effective_length)\n                else:\n                    start = 0\n                y = y[start:start + effective_length].astype(np.float32)\n            else:\n                y = y.astype(np.float32)\n\n            y = np.nan_to_num(y)\n\n            labels = primary_label\n            labels = labels.astype(np.int_)\n\n            return {\n                \"image\": y,\n                \"targets\": labels\n            }\n        \n        else:\n            sample = self.df.loc[idx, :]\n            print(sample)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.466230Z","iopub.execute_input":"2022-04-26T16:29:03.466850Z","iopub.status.idle":"2022-04-26T16:29:03.481710Z","shell.execute_reply.started":"2022-04-26T16:29:03.466813Z","shell.execute_reply":"2022-04-26T16:29:03.480947Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"from torchlibrosa.stft import Spectrogram, LogmelFilterBank\nfrom torchlibrosa.augmentation import SpecAugmentation\n\ndef do_mixup(x, mixup_lambda):\n    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes\n    (1, 3, 5, ...).\n\n    Args:\n      x: (batch_size * 2, ...)\n      mixup_lambda: (batch_size * 2,)\n\n    Returns:\n      out: (batch_size, ...)\n    \"\"\"\n    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n    return out\n\n\ndef init_layer(layer):\n    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n    nn.init.xavier_uniform_(layer.weight)\n\n    if hasattr(layer, 'bias'):\n        if layer.bias is not None:\n            layer.bias.data.fill_(0.)\n\n\ndef init_bn(bn):\n    \"\"\"Initialize a Batchnorm layer. \"\"\"\n    bn.bias.data.fill_(0.)\n    bn.weight.data.fill_(1.)\n\n    \nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n\n        super(ConvBlock, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels=in_channels,\n                               out_channels=out_channels,\n                               kernel_size=(3, 3), stride=(1, 1),\n                               padding=(1, 1), bias=False)\n\n        self.conv2 = nn.Conv2d(in_channels=out_channels,\n                               out_channels=out_channels,\n                               kernel_size=(3, 3), stride=(1, 1),\n                               padding=(1, 1), bias=False)\n\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.conv1)\n        init_layer(self.conv2)\n        init_bn(self.bn1)\n        init_bn(self.bn2)\n\n    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n\n        x = input\n        x = F.relu_(self.bn1(self.conv1(x)))\n        x = F.relu_(self.bn2(self.conv2(x)))\n        if pool_type == 'max':\n            x = F.max_pool2d(x, kernel_size=pool_size)\n        elif pool_type == 'avg':\n            x = F.avg_pool2d(x, kernel_size=pool_size)\n        elif pool_type == 'avg+max':\n            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n            x2 = F.max_pool2d(x, kernel_size=pool_size)\n            x = x1 + x2\n        else:\n            raise Exception('Incorrect argument!')\n\n        return x\n\nclass Cnn14(nn.Module):\n    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n        fmax, classes_num):\n        \n        super(Cnn14, self).__init__()\n\n        window = 'hann'\n        center = True\n        pad_mode = 'reflect'\n        ref = 1.0\n        amin = 1e-10\n        top_db = None\n\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n            freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n            freeze_parameters=True)\n\n        # Spec augmenter\n        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n            freq_drop_width=8, freq_stripes_num=2)\n\n        self.bn0 = nn.BatchNorm2d(512)\n\n        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n\n        self.fc1 = nn.Linear(2048, 2048, bias=True)\n        self.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n        \n        self.init_weight()\n\n    def init_weight(self):\n        init_bn(self.bn0)\n        init_layer(self.fc1)\n        init_layer(self.fc_audioset)\n \n    def forward(self, input, mixup_lambda=None):\n        \"\"\"\n        Input: (batch_size, data_length)\"\"\"\n        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n        \n#         x = x.transpose(1, 3)\n#         x = self.bn0(x)\n#         x = x.transpose(1, 3)\n#         img = x[0][0].detach().cpu()\n#         print(img.shape, x.shape)\n#         plt.imshow(np.transpose(img))\n#         plt.show()\n\n        if self.training:\n            x = self.spec_augmenter(x)\n\n        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = torch.mean(x, dim=3)\n        \n        (x1, _) = torch.max(x, dim=2)\n        x2 = torch.mean(x, dim=2)\n        x = x1 + x2\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = F.relu_(self.fc1(x))\n        embedding = F.dropout(x, p=0.5, training=self.training)\n        clipwise_output = torch.sigmoid(self.fc_audioset(x))\n        \n        output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n\n        return output_dict\n    \n    \nclass Transfer_Cnn14(nn.Module):\n    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n        fmax, classes_num, freeze_base):\n        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n        \"\"\"\n        super(Transfer_Cnn14, self).__init__()\n        audioset_classes_num = 152\n        \n        self.base = Cnn14(sample_rate, window_size, hop_size, mel_bins, fmin, \n            fmax, audioset_classes_num)\n\n        # Transfer to another task layer\n        self.fc_transfer = nn.Linear(2048, classes_num, bias=True)\n\n        if freeze_base:\n            # Freeze AudioSet pretrained layers\n            for param in self.base.parameters():\n                param.requires_grad = False\n\n        self.init_weights()\n\n    def init_weights(self):\n        init_layer(self.fc_transfer)\n\n    def load_from_pretrain(self, pretrained_checkpoint_path):\n        checkpoint = torch.load(pretrained_checkpoint_path)\n        self.base.load_state_dict(checkpoint['model'])\n\n    def forward(self, input, mixup_lambda=None):\n        \"\"\"Input: (batch_size, data_length)\n        \"\"\"\n        output_dict = self.base(input, mixup_lambda)\n        embedding = output_dict['embedding']\n\n        clipwise_output =  self.fc_transfer(embedding)\n#         print(clipwise_output.shape)\n \n        return clipwise_output","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.483354Z","iopub.execute_input":"2022-04-26T16:29:03.483913Z","iopub.status.idle":"2022-04-26T16:29:03.521698Z","shell.execute_reply.started":"2022-04-26T16:29:03.483877Z","shell.execute_reply":"2022-04-26T16:29:03.521024Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# sample_rate, window_size, hop_size, mel_bins, fmin, fmax,        classes_num, freeze_base\nclass PANNConfig:\n    seed = 2022 \n    num_classes = 152\n    epochs = 1\n    batch_size = 32\n    n_fold = 5 \n    learning_rate = 1e-4 \n    img_size = 224 \n    print_freq = 1\n    model_save_dir = './'\n    pretrained = True\n    \n    pretrained_model = \"Cnn14_emb128_mAP=0.412.pth\"\n    sampling_rate = 16000\n    window_size = 512\n    hop_size = 160\n    mel_bins = 512\n    fmin = 50\n    fmax = 8000\n    classes_num = num_classes\n    freeze_base = True\n    \ncfg = PANNConfig()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.522717Z","iopub.execute_input":"2022-04-26T16:29:03.523047Z","iopub.status.idle":"2022-04-26T16:29:03.534063Z","shell.execute_reply.started":"2022-04-26T16:29:03.523006Z","shell.execute_reply":"2022-04-26T16:29:03.533375Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Training Utils","metadata":{}},{"cell_type":"code","source":"# Custom optimizer\n__OPTIMIZERS__ = {}\n\ndef get_optimizer(model: nn.Module):\n    optimizer_name = CFG.optimizer_name\n    if optimizer_name == \"SAM\":\n        base_optimizer_name = CFG.base_optimizer\n        if __OPTIMIZERS__.get(base_optimizer_name) is not None:\n            base_optimizer = __OPTIMIZERS__[base_optimizer_name]\n        else:\n            base_optimizer = optim.__getattribute__(base_optimizer_name)\n        return SAM(model.parameters(), base_optimizer, **CFG.optimizer_params)\n\n    if __OPTIMIZERS__.get(optimizer_name) is not None:\n        return __OPTIMIZERS__[optimizer_name](model.parameters(),\n                                              **CFG.optimizer_params)\n    else:\n        return optim.__getattribute__(optimizer_name)(model.parameters(),\n                                                      **CFG.optimizer_params)\n\ndef get_scheduler(optimizer):\n    scheduler_name = CFG.scheduler_name\n\n    if scheduler_name is None:\n        return\n    else:\n        return optim.lr_scheduler.__getattribute__(scheduler_name)(\n            optimizer, **CFG.scheduler_params)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.535370Z","iopub.execute_input":"2022-04-26T16:29:03.535894Z","iopub.status.idle":"2022-04-26T16:29:03.544747Z","shell.execute_reply.started":"2022-04-26T16:29:03.535857Z","shell.execute_reply":"2022-04-26T16:29:03.544072Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"# environment\nset_seed(CFG.seed)\n# validation\nsplitter = getattr(model_selection, CFG.split)(**CFG.split_params)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.545910Z","iopub.execute_input":"2022-04-26T16:29:03.546776Z","iopub.status.idle":"2022-04-26T16:29:03.559132Z","shell.execute_reply.started":"2022-04-26T16:29:03.546740Z","shell.execute_reply":"2022-04-26T16:29:03.558427Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(MAIN_DATA_DIR / 'train_metadata.csv')\ntrain['secondary_labels'] = [ast.literal_eval(d) for d in train['secondary_labels']]\nprint(train.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.560293Z","iopub.execute_input":"2022-04-26T16:29:03.560718Z","iopub.status.idle":"2022-04-26T16:29:03.777401Z","shell.execute_reply.started":"2022-04-26T16:29:03.560668Z","shell.execute_reply":"2022-04-26T16:29:03.776608Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"## Let's reduce the training datasize\n# We can keep 10 recordings per BIRD class\nN = 40\ntrain = train.iloc[np.random.permutation(len(train))]\nnew_train = train.groupby('primary_label').apply(lambda x: x[:N])\nnew_train.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.778812Z","iopub.execute_input":"2022-04-26T16:29:03.779279Z","iopub.status.idle":"2022-04-26T16:29:03.896332Z","shell.execute_reply.started":"2022-04-26T16:29:03.779241Z","shell.execute_reply":"2022-04-26T16:29:03.895571Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train = new_train.copy()\ndel new_train\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.897519Z","iopub.execute_input":"2022-04-26T16:29:03.898127Z","iopub.status.idle":"2022-04-26T16:29:03.908301Z","shell.execute_reply.started":"2022-04-26T16:29:03.898087Z","shell.execute_reply":"2022-04-26T16:29:03.907432Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"labels_total = []\nfor ebird_code in train['primary_label']:\n    labels = np.zeros(len(CFG.target_columns), dtype=float)\n    labels[CFG.target_columns.index(ebird_code)] = 1.0\n    labels_total.append(labels)\n\ntrain['primary_labels'] = labels_total","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.909357Z","iopub.execute_input":"2022-04-26T16:29:03.910034Z","iopub.status.idle":"2022-04-26T16:29:03.940157Z","shell.execute_reply.started":"2022-04-26T16:29:03.909996Z","shell.execute_reply":"2022-04-26T16:29:03.939501Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:29:03.942580Z","iopub.execute_input":"2022-04-26T16:29:03.942762Z","iopub.status.idle":"2022-04-26T16:29:03.965787Z","shell.execute_reply.started":"2022-04-26T16:29:03.942740Z","shell.execute_reply":"2022-04-26T16:29:03.964996Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Learner class(pytorch-lighting)\nclass Learner(pl.LightningModule):\n    def __init__(self, model, num_train_steps, num_warmup_steps):\n        super().__init__()\n        self.model_ = model\n        self.criterion = nn.CrossEntropyLoss()\n        self.num_train_steps = num_train_steps\n        self.num_warmup_steps = num_warmup_steps\n    \n    def training_step(self, batch, batch_idx):\n        b_data = batch\n        output = self.model_(b_data['image'])\n        loss = self.criterion(output, torch.max(b_data[\"targets\"], 1)[1])\n        \n        clipwise_output_np = to_np(output)\n        targets_np = to_np(b_data[\"targets\"])\n\n        f1_score_3 = metrics.f1_score(targets_np > 0.5, clipwise_output_np > 0.3, average=\"samples\")\n        f1_score_5 = metrics.f1_score(targets_np > 0.5, clipwise_output_np > 0.5, average=\"samples\")\n#         print(clipwise_output_np.argmax(1), targets_np.argmax(1), f1_score_5)\n        \n        self.log(f'Loss/train', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n        self.log(f'F1_03/train', f1_score_3, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n        self.log(f'F1_05/train', f1_score_5, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n        \n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        b_data = batch\n        output = self.model_(b_data['image'])\n        loss = self.criterion(output, torch.max(b_data[\"targets\"], 1)[1])\n        \n        clipwise_output_np = to_np(output)\n        targets_np = to_np(b_data[\"targets\"])\n        f1_score_3 = metrics.f1_score(targets_np > 0.5, clipwise_output_np > 0.3, average=\"samples\")\n        f1_score_5 = metrics.f1_score(targets_np > 0.5, clipwise_output_np > 0.5, average=\"samples\")\n\n        self.log(f'Loss/val', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n        self.log(f'F1_03/val', f1_score_3, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n        self.log(f'F1_05/val', f1_score_5, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n        \n        return loss\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x for x in outputs]).mean()\n        print(f'epoch = {self.current_epoch}, loss = {avg_loss}')\n\n    def configure_optimizers(self):\n        optimizer = get_optimizer(self.model_)\n        scheduler = get_scheduler(optimizer)\n        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"Loss/val\"}","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:31:51.702099Z","iopub.execute_input":"2022-04-26T16:31:51.702365Z","iopub.status.idle":"2022-04-26T16:31:51.718859Z","shell.execute_reply.started":"2022-04-26T16:31:51.702337Z","shell.execute_reply":"2022-04-26T16:31:51.716724Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def to_np(input):\n    return input.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:31:52.507254Z","iopub.execute_input":"2022-04-26T16:31:52.507804Z","iopub.status.idle":"2022-04-26T16:31:52.511722Z","shell.execute_reply.started":"2022-04-26T16:31:52.507765Z","shell.execute_reply":"2022-04-26T16:31:52.510730Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nfor i, (trn_idx, val_idx) in enumerate(splitter.split(train, y=train[\"primary_label\"])):\n    if i not in CFG.folds:\n        continue\n\n    trn_df = train.loc[trn_idx, :].reset_index(drop=True)\n    val_df = train.loc[val_idx, :].reset_index(drop=True)\n    \n    loaders = {\n        phase: torchdata.DataLoader(\n            WaveformDataset(\n                df_,\n                train_datadir,\n                img_size=CFG.img_size,\n                period=CFG.period,\n                validation=(phase == \"valid\"),\n                test=False\n            ),\n            **CFG.loader_params[phase])  # type: ignore\n        for phase, df_ in zip([\"train\", \"valid\"], [trn_df, val_df])\n    }\n    \n    num_train_steps = int(len(loaders['train']) * CFG.epochs)\n    num_warmup_steps = int(num_train_steps / 10)    \n    \n    model = Transfer_Cnn14(cfg.sampling_rate, cfg.window_size, cfg.hop_size, cfg.mel_bins, cfg.fmin, cfg.fmax, cfg.classes_num, cfg.freeze_base).to(device)\n    model_name = model.__class__.__name__\n    print(model_name)\n    \n    learner = Learner(model, num_train_steps, num_warmup_steps)\n    \n    # loggers\n    RUN_NAME = f'exp{str(CFG.exp_num)}'\n    wandb.init(project='BirdCLEF22-Experiment-PANN', entity='cknwandb', group=RUN_NAME, job_type=RUN_NAME + f'-fold-{i}')\n    wandb_config = wandb.config\n    wandb_config.model_name = model_name\n    wandb.watch(model)\n    \n    # callbacks\n    callbacks = []\n    checkpoint_callback = ModelCheckpoint(\n        monitor=f'Loss/val',\n        mode='min',\n        dirpath=OUTPUT_DIR,\n        verbose=False,\n        filename=f'{model_name}-{learner.current_epoch}-{i}')\n    callbacks.append(checkpoint_callback)\n\n    early_stop_callback = EarlyStopping(\n        monitor='Loss/val',\n        min_delta=0.00,\n        patience=20,\n        verbose=True,\n        mode='min')\n    callbacks.append(early_stop_callback)\n    \n    loggers = []\n    loggers.append(WandbLogger())\n    \n    trainer = pl.Trainer(\n        logger=loggers,\n        callbacks=callbacks,\n        max_epochs=CFG.epochs,\n        default_root_dir=OUTPUT_DIR,\n        gpus=1,\n        deterministic=True,\n        benchmark=False\n        )\n    \n    trainer.fit(learner, train_dataloader=loaders['train'], val_dataloaders=loaders['valid'])\n    trainer.save_checkpoint(OUTPUT_DIR / \"last.ckpt\")\n    \nwandb.init(project='BirdCLEF22-Experiment-PANN', entity='cknwandb', group=RUN_NAME, job_type='summary')\nwandb.run.name = 'summary'\nwandb.save('./config_.py')\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:31:52.874287Z","iopub.execute_input":"2022-04-26T16:31:52.874965Z","iopub.status.idle":"2022-04-26T16:33:10.457961Z","shell.execute_reply.started":"2022-04-26T16:31:52.874926Z","shell.execute_reply":"2022-04-26T16:33:10.457215Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# import glob\n# test_audios = list(glob.glob(\"../input/birdclef-2022/test_soundscapes/*.ogg\"))\n# sample_submission = pd.read_csv('../input/birdclef-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:33:10.460236Z","iopub.execute_input":"2022-04-26T16:33:10.460632Z","iopub.status.idle":"2022-04-26T16:33:10.465472Z","shell.execute_reply.started":"2022-04-26T16:33:10.460592Z","shell.execute_reply":"2022-04-26T16:33:10.463532Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# threshold = 0.2\n# new_model = ASTModel(label_dim=CFG.num_classes, \n#          input_fdim=CFG.n_mels, \n#          input_tdim=626, \n#          audioset_pretrain=True, \n#          model_size='base384', \n#          verbose=True).to(device)\n# learner = Learner(model, num_train_steps, num_warmup_steps)\n# checkpoint = torch.load('./last.ckpt')\n# learner.load_state_dict(checkpoint['state_dict'])\n# new_model = learner.model_.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:30:18.869946Z","iopub.execute_input":"2022-04-26T16:30:18.872540Z","iopub.status.idle":"2022-04-26T16:30:19.334210Z","shell.execute_reply.started":"2022-04-26T16:30:18.872500Z","shell.execute_reply":"2022-04-26T16:30:19.333187Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# for audio_path in test_audios:\n#     print(audio_path)\n#     seconds = []\n#     row_ids = []\n#     for second in range(10, 65, 10):\n#         row_id = audio_path.split(\"/\")[-1][:-4] + f\"_{second}\"\n#         seconds.append(second)\n#         row_ids.append(row_id)\n#     print(row_ids)\n#     test_df = pd.DataFrame({\"filename\": audio_path, \"row_id\": row_ids, \"seconds\": seconds})","metadata":{"execution":{"iopub.status.busy":"2022-04-26T16:30:19.335822Z","iopub.execute_input":"2022-04-26T16:30:19.336521Z","iopub.status.idle":"2022-04-26T16:30:19.342661Z","shell.execute_reply.started":"2022-04-26T16:30:19.336431Z","shell.execute_reply":"2022-04-26T16:30:19.341848Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}